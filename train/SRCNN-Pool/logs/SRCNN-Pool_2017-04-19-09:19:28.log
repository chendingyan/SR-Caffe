I0419 09:19:28.433781 103546 caffe.cpp:218] Using GPUs 0
I0419 09:19:28.442543 103546 caffe.cpp:223] GPU 0: Quadro K6000
I0419 09:19:28.835340 103546 solver.cpp:44] Initializing solver from parameters: 
test_iter: 556
test_interval: 500
base_lr: 0.001
display: 100
max_iter: 15000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0
snapshot: 5000
snapshot_prefix: "caffemodel/SRCNN-Pool"
solver_mode: GPU
device_id: 0
net: "SRCNN_train.prototxt"
train_state {
  level: 0
  stage: ""
}
I0419 09:19:28.835557 103546 solver.cpp:87] Creating training net from net file: SRCNN_train.prototxt
I0419 09:19:28.835914 103546 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0419 09:19:28.836020 103546 net.cpp:51] Initializing net from parameters: 
name: "SRCNN"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "train.txt"
    batch_size: 128
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 0.1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 1
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "conv3"
  bottom: "label"
  top: "loss"
}
I0419 09:19:28.836099 103546 layer_factory.hpp:77] Creating layer data
I0419 09:19:28.836122 103546 net.cpp:84] Creating Layer data
I0419 09:19:28.836133 103546 net.cpp:380] data -> data
I0419 09:19:28.836159 103546 net.cpp:380] data -> label
I0419 09:19:28.836174 103546 hdf5_data_layer.cpp:80] Loading list of HDF5 filenames from: train.txt
I0419 09:19:28.836210 103546 hdf5_data_layer.cpp:94] Number of HDF5 files: 1
I0419 09:19:28.837244 103546 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0419 09:19:28.982446 103546 net.cpp:122] Setting up data
I0419 09:19:28.982498 103546 net.cpp:129] Top shape: 128 1 33 33 (139392)
I0419 09:19:28.982507 103546 net.cpp:129] Top shape: 128 1 21 21 (56448)
I0419 09:19:28.982511 103546 net.cpp:137] Memory required for data: 783360
I0419 09:19:28.982525 103546 layer_factory.hpp:77] Creating layer conv1
I0419 09:19:28.982554 103546 net.cpp:84] Creating Layer conv1
I0419 09:19:28.982563 103546 net.cpp:406] conv1 <- data
I0419 09:19:28.982580 103546 net.cpp:380] conv1 -> conv1
I0419 09:19:28.984046 103546 net.cpp:122] Setting up conv1
I0419 09:19:28.984068 103546 net.cpp:129] Top shape: 128 64 31 31 (7872512)
I0419 09:19:28.984073 103546 net.cpp:137] Memory required for data: 32273408
I0419 09:19:28.984091 103546 layer_factory.hpp:77] Creating layer relu1
I0419 09:19:28.984103 103546 net.cpp:84] Creating Layer relu1
I0419 09:19:28.984110 103546 net.cpp:406] relu1 <- conv1
I0419 09:19:28.984117 103546 net.cpp:367] relu1 -> conv1 (in-place)
I0419 09:19:28.984133 103546 net.cpp:122] Setting up relu1
I0419 09:19:28.984163 103546 net.cpp:129] Top shape: 128 64 31 31 (7872512)
I0419 09:19:28.984167 103546 net.cpp:137] Memory required for data: 63763456
I0419 09:19:28.984171 103546 layer_factory.hpp:77] Creating layer pool1
I0419 09:19:28.984179 103546 net.cpp:84] Creating Layer pool1
I0419 09:19:28.984184 103546 net.cpp:406] pool1 <- conv1
I0419 09:19:28.984190 103546 net.cpp:380] pool1 -> pool1
I0419 09:19:28.984246 103546 net.cpp:122] Setting up pool1
I0419 09:19:28.984257 103546 net.cpp:129] Top shape: 128 64 16 16 (2097152)
I0419 09:19:28.984261 103546 net.cpp:137] Memory required for data: 72152064
I0419 09:19:28.984266 103546 layer_factory.hpp:77] Creating layer conv2
I0419 09:19:28.984278 103546 net.cpp:84] Creating Layer conv2
I0419 09:19:28.984283 103546 net.cpp:406] conv2 <- pool1
I0419 09:19:28.984290 103546 net.cpp:380] conv2 -> conv2
I0419 09:19:28.986390 103546 net.cpp:122] Setting up conv2
I0419 09:19:28.986409 103546 net.cpp:129] Top shape: 128 64 14 14 (1605632)
I0419 09:19:28.986413 103546 net.cpp:137] Memory required for data: 78574592
I0419 09:19:28.986423 103546 layer_factory.hpp:77] Creating layer relu2
I0419 09:19:28.986431 103546 net.cpp:84] Creating Layer relu2
I0419 09:19:28.986436 103546 net.cpp:406] relu2 <- conv2
I0419 09:19:28.986443 103546 net.cpp:367] relu2 -> conv2 (in-place)
I0419 09:19:28.986450 103546 net.cpp:122] Setting up relu2
I0419 09:19:28.986455 103546 net.cpp:129] Top shape: 128 64 14 14 (1605632)
I0419 09:19:28.986459 103546 net.cpp:137] Memory required for data: 84997120
I0419 09:19:28.986462 103546 layer_factory.hpp:77] Creating layer pool2
I0419 09:19:28.986469 103546 net.cpp:84] Creating Layer pool2
I0419 09:19:28.986472 103546 net.cpp:406] pool2 <- conv2
I0419 09:19:28.986479 103546 net.cpp:380] pool2 -> pool2
I0419 09:19:28.986521 103546 net.cpp:122] Setting up pool2
I0419 09:19:28.986528 103546 net.cpp:129] Top shape: 128 64 7 7 (401408)
I0419 09:19:28.986532 103546 net.cpp:137] Memory required for data: 86602752
I0419 09:19:28.986536 103546 layer_factory.hpp:77] Creating layer conv3
I0419 09:19:28.986547 103546 net.cpp:84] Creating Layer conv3
I0419 09:19:28.986552 103546 net.cpp:406] conv3 <- pool2
I0419 09:19:28.986558 103546 net.cpp:380] conv3 -> conv3
I0419 09:19:28.986796 103546 net.cpp:122] Setting up conv3
I0419 09:19:28.986809 103546 net.cpp:129] Top shape: 128 1 5 5 (3200)
I0419 09:19:28.986812 103546 net.cpp:137] Memory required for data: 86615552
I0419 09:19:28.986822 103546 layer_factory.hpp:77] Creating layer loss
I0419 09:19:28.986838 103546 net.cpp:84] Creating Layer loss
I0419 09:19:28.986842 103546 net.cpp:406] loss <- conv3
I0419 09:19:28.986847 103546 net.cpp:406] loss <- label
I0419 09:19:28.986855 103546 net.cpp:380] loss -> loss
F0419 09:19:28.986881 103546 euclidean_loss_layer.cpp:12] Check failed: bottom[0]->count(1) == bottom[1]->count(1) (25 vs. 441) Inputs must have the same dimension.
*** Check failure stack trace: ***
    @     0x7f2eedcd6daa  (unknown)
    @     0x7f2eedcd6ce4  (unknown)
    @     0x7f2eedcd66e6  (unknown)
    @     0x7f2eedcd9687  (unknown)
    @     0x7f2eee3b75fa  caffe::EuclideanLossLayer<>::Reshape()
    @     0x7f2eee418f65  caffe::Net<>::Init()
    @     0x7f2eee41ae62  caffe::Net<>::Net()
    @     0x7f2eee430b40  caffe::Solver<>::InitTrainNet()
    @     0x7f2eee431a93  caffe::Solver<>::Init()
    @     0x7f2eee431d6f  caffe::Solver<>::Solver()
    @     0x7f2eee3f90c1  caffe::Creator_SGDSolver<>()
    @           0x40ee6e  caffe::SolverRegistry<>::CreateSolver()
    @           0x407efd  train()
    @           0x40590c  main
    @     0x7f2eecce2f45  (unknown)
    @           0x40617b  (unknown)
    @              (nil)  (unknown)
